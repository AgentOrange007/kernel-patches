From dd825d35dafb2987580138abf91ff466d1574b45 Mon Sep 17 00:00:00 2001
From: Piotr Gorski <lucjan.lucjanov@gmail.com>
Date: Tue, 25 Jun 2019 22:02:28 +0200
Subject: [PATCH] LL: Implement ll-branding v5.1

Signed-off-by: Piotr Gorski <lucjan.lucjanov@gmail.com>
---
 block/elevator.c       |  8 ++++++++
 include/linux/blkdev.h |  4 ++++
 init/Kconfig           |  4 ++++
 kernel/sched/core.c    |  8 ++++++++
 kernel/sched/fair.c    | 25 +++++++++++++++++++++++++
 5 files changed, 49 insertions(+)

diff --git a/block/elevator.c b/block/elevator.c
index d6d835a08..32dd19128 100644
--- a/block/elevator.c
+++ b/block/elevator.c
@@ -605,8 +605,10 @@ int elevator_init_mq(struct request_queue *q)
 	struct elevator_type *e;
 	int err = 0;
 
+#ifndef CONFIG_LL_BRANDING
 	if (q->nr_hw_queues != 1)
 		return 0;
+#endif
 
 	/*
 	 * q->sysfs_lock must be held to provide mutual exclusion between
@@ -616,7 +618,13 @@ int elevator_init_mq(struct request_queue *q)
 	if (unlikely(q->elevator))
 		goto out_unlock;
 
+#if defined(CONFIG_LL_BRANDING) && defined(CONFIG_MQ_IOSCHED_BFQ)
+	e = elevator_get(q, "bfq-mq", false);
+#elif defined(CONFIG_LL_BRANDING) && defined(CONFIG_IOSCHED_BFQ)
+	e = elevator_get(q, "bfq", false);
+#else
 	e = elevator_get(q, "mq-deadline", false);
+#endif
 	if (!e)
 		goto out_unlock;
 
diff --git a/include/linux/blkdev.h b/include/linux/blkdev.h
index 317ab30d2..3483292d5 100644
--- a/include/linux/blkdev.h
+++ b/include/linux/blkdev.h
@@ -45,7 +45,11 @@ struct blk_queue_stats;
 struct blk_stat_callback;
 
 #define BLKDEV_MIN_RQ	4
+#ifdef CONFIG_LL_BRANDING
+#define BLKDEV_MAX_RQ	512
+#else
 #define BLKDEV_MAX_RQ	128	/* Default maximum */
+#endif
 
 /* Must be consistent with blk_mq_poll_stats_bkt() */
 #define BLK_MQ_POLL_STATS_BKTS 16
diff --git a/init/Kconfig b/init/Kconfig
index 4592bf799..07dcf64e5 100644
--- a/init/Kconfig
+++ b/init/Kconfig
@@ -64,6 +64,10 @@ config THREAD_INFO_IN_TASK
 
 menu "General setup"
 
+config LL_BRANDING
+	bool "Add Linux Lucjan branding"
+	default y
+
 config BROKEN
 	bool
 
diff --git a/kernel/sched/core.c b/kernel/sched/core.c
index a75ad50b5..57a9918d8 100644
--- a/kernel/sched/core.c
+++ b/kernel/sched/core.c
@@ -44,7 +44,11 @@ const_debug unsigned int sysctl_sched_features =
  * Number of tasks to iterate in a single balance run.
  * Limited because this is done with IRQs disabled.
  */
+#ifdef CONFIG_LL_BRANDING
+const_debug unsigned int sysctl_sched_nr_migrate = 128;
+#else
 const_debug unsigned int sysctl_sched_nr_migrate = 32;
+#endif
 
 /*
  * period over which we measure -rt task CPU usage in us.
@@ -58,7 +62,11 @@ __read_mostly int scheduler_running;
  * part of the period that we allow rt tasks to run in us.
  * default: 0.95s
  */
+#ifdef CONFIG_LL_BRANDING
+int sysctl_sched_rt_runtime = 980000;
+#else
 int sysctl_sched_rt_runtime = 950000;
+#endif
 
 /*
  * __task_rq_lock - lock the rq @p resides on.
diff --git a/kernel/sched/fair.c b/kernel/sched/fair.c
index 232491e3e..4cc98c9db 100644
--- a/kernel/sched/fair.c
+++ b/kernel/sched/fair.c
@@ -37,8 +37,13 @@
  *
  * (default: 6ms * (1 + ilog(ncpus)), units: nanoseconds)
  */
+#ifdef CONFIG_LL_BRANDING
+unsigned int sysctl_sched_latency			= 4000000ULL;
+static unsigned int normalized_sysctl_sched_latency	= 4000000ULL;
+#else
 unsigned int sysctl_sched_latency			= 6000000ULL;
 static unsigned int normalized_sysctl_sched_latency	= 6000000ULL;
+#endif
 
 /*
  * The initial- and re-scaling of tunables is configurable
@@ -58,13 +63,22 @@ enum sched_tunable_scaling sysctl_sched_tunable_scaling = SCHED_TUNABLESCALING_L
  *
  * (default: 0.75 msec * (1 + ilog(ncpus)), units: nanoseconds)
  */
+#ifdef CONFIG_LL_BRANDING
+unsigned int sysctl_sched_min_granularity			= 400000ULL;
+static unsigned int normalized_sysctl_sched_min_granularity	= 400000ULL;
+#else
 unsigned int sysctl_sched_min_granularity			= 750000ULL;
 static unsigned int normalized_sysctl_sched_min_granularity	= 750000ULL;
+#endif
 
 /*
  * This value is kept at sysctl_sched_latency/sysctl_sched_min_granularity
  */
+#ifdef CONFIG_LL_BRANDING
+static unsigned int sched_nr_latency = 10;
+#else
 static unsigned int sched_nr_latency = 8;
+#endif
 
 /*
  * After fork, child runs first. If set to 0 (default) then
@@ -81,10 +95,17 @@ unsigned int sysctl_sched_child_runs_first __read_mostly;
  *
  * (default: 1 msec * (1 + ilog(ncpus)), units: nanoseconds)
  */
+#ifdef CONFIG_LL_BRANDING
+unsigned int sysctl_sched_wakeup_granularity			= 500000UL;
+static unsigned int normalized_sysctl_sched_wakeup_granularity	= 500000UL;
+
+const_debug unsigned int sysctl_sched_migration_cost	= 250000UL;
+#else
 unsigned int sysctl_sched_wakeup_granularity			= 1000000UL;
 static unsigned int normalized_sysctl_sched_wakeup_granularity	= 1000000UL;
 
 const_debug unsigned int sysctl_sched_migration_cost	= 500000UL;
+#endif
 
 #ifdef CONFIG_SMP
 /*
@@ -115,8 +136,12 @@ static unsigned int capacity_margin			= 1280;
  *
  * (default: 5 msec, units: microseconds)
  */
+#ifdef CONFIG_LL_BRANDING
+unsigned int sysctl_sched_cfs_bandwidth_slice		= 3000UL;
+#else
 unsigned int sysctl_sched_cfs_bandwidth_slice		= 5000UL;
 #endif
+#endif
 
 static inline void update_load_add(struct load_weight *lw, unsigned long inc)
 {
-- 
2.22.0.190.ga6a95cd1b4

