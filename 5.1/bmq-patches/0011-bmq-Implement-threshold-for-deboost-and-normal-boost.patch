From de1b363949b20b2c7f0774c6a914fe9d08621ac6 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Mon, 11 Mar 2019 11:09:52 +0800
Subject: [PATCH 11/43] bmq: Implement threshold for deboost and normal boost.

---
 kernel/sched/bmq.c | 41 +++++++++++++++++++++++++++++++++++------
 1 file changed, 35 insertions(+), 6 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index f3841edcc6fd..0d3a73dabb45 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -66,9 +66,37 @@ static inline void print_scheduler_version(void)
  */
 int sched_yield_type __read_mostly = 1;
 
-static inline int ts_over_run(struct rq *rq)
-{
-	return (rq->clock - rq->last_ts_switch > SCHED_TIMESLICE_NS * 3 / 4);
+static inline int ts_overrun(struct task_struct *p, struct rq *rq)
+{
+	const static u64 ts_overrun_th[] = {
+		SCHED_TIMESLICE_NS / 2,
+		SCHED_TIMESLICE_NS / 2,
+		SCHED_TIMESLICE_NS / 2,
+		SCHED_TIMESLICE_NS / 2,
+		SCHED_TIMESLICE_NS * 3 / 4,
+		SCHED_TIMESLICE_NS * 7 / 8,
+		SCHED_TIMESLICE_NS * 15 / 16,
+		SCHED_TIMESLICE_NS * 31 / 32,
+		SCHED_TIMESLICE_NS * 63 / 64};
+	return (rq->clock - rq->last_ts_switch >
+		ts_overrun_th[MAX_PRIORITY_ADJ + p->boost_prio]);
+}
+
+static inline int task_normal_boost(struct task_struct *p, struct rq *rq)
+{
+	const static u64 ts_nonboost_th[] = {
+		SCHED_TIMESLICE_NS << 7,
+		SCHED_TIMESLICE_NS << 6,
+		SCHED_TIMESLICE_NS << 5,
+		SCHED_TIMESLICE_NS << 4,
+		SCHED_TIMESLICE_NS << 3,
+		SCHED_TIMESLICE_NS << 3,
+		SCHED_TIMESLICE_NS << 3,
+		SCHED_TIMESLICE_NS << 3,
+		SCHED_TIMESLICE_NS << 3
+	};
+	return ((rq->clock - rq->last_ts_switch) >
+		ts_nonboost_th[MAX_PRIORITY_ADJ + p->boost_prio]);
 }
 
 #ifdef CONFIG_SMP
@@ -2826,7 +2854,7 @@ static inline void check_curr(struct task_struct *p, struct rq *rq)
 		p->time_slice = SCHED_TIMESLICE_NS;
 		if (SCHED_FIFO != p->policy && task_on_rq_queued(p)) {
 			if (SCHED_RR != p->policy &&
-			    (p->ts_deboost || ts_over_run(rq)))
+			    (p->ts_deboost || ts_overrun(p, rq)))
 				deboost_task(p, MAX_PRIORITY_ADJ);
 			requeue_task(p, rq);
 		}
@@ -3083,8 +3111,9 @@ static void __sched notrace __schedule(bool preempt)
 		if (signal_pending_state(prev->state, prev)) {
 			prev->state = TASK_RUNNING;
 		} else {
-			prev->ts_deboost |= ts_over_run(rq);
-			if ((SCHED_NORMAL == prev->policy && prev->ts_deboost) ||
+			prev->ts_deboost |= ts_overrun(prev, rq);
+			if ((SCHED_NORMAL == prev->policy &&
+			     task_normal_boost(prev, rq)) ||
 			    SCHED_BATCH == prev->policy ||
 			    SCHED_IDLE == prev->policy)
 				deboost_task(prev, 1);
-- 
2.21.0.777.g83232e3864

