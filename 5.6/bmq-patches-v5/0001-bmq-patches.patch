From 0761e7e82af6b9e8c43435a69f8b73e85a684471 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Sat, 21 Mar 2020 15:33:54 +0800
Subject: [PATCH 1/2] bmq: Fix incorrect rq->sched_goidle statistics.

---
 kernel/sched/bmq.c | 25 ++++++++++++-------------
 1 file changed, 12 insertions(+), 13 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index fed5e132f2af..0a9a56e3312a 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -3231,6 +3231,9 @@ static inline int take_other_rq_tasks(struct rq *rq, int cpu)
 {
 	struct cpumask *affinity_mask, *end_mask;
 
+	if (unlikely(!rq->online))
+		return 0;
+
 	if (cpumask_empty(&sched_rq_pending_mask))
 		return 0;
 
@@ -3293,9 +3296,8 @@ choose_next_task(struct rq *rq, int cpu, struct task_struct *prev)
 	if (unlikely(rq->skip)) {
 		next = rq_runnable_task(rq);
 #ifdef	CONFIG_SMP
-		if (likely(rq->online))
-			if (next == rq->idle && take_other_rq_tasks(rq, cpu))
-				next = rq_runnable_task(rq);
+		if (next == rq->idle && take_other_rq_tasks(rq, cpu))
+			next = rq_runnable_task(rq);
 #endif
 		rq->skip = NULL;
 		return next;
@@ -3303,9 +3305,8 @@ choose_next_task(struct rq *rq, int cpu, struct task_struct *prev)
 
 	next = rq_first_bmq_task(rq);
 #ifdef	CONFIG_SMP
-	if (likely(rq->online))
-		if (next == rq->idle && take_other_rq_tasks(rq, cpu))
-			return rq_first_bmq_task(rq);
+	if (next == rq->idle && take_other_rq_tasks(rq, cpu))
+		return rq_first_bmq_task(rq);
 #endif
 	return next;
 }
@@ -3316,8 +3317,11 @@ static inline void set_rq_task(struct rq *rq, struct task_struct *p)
 
 	if (unlikely(sched_timeslice_ns == p->time_slice))
 		rq->last_ts_switch = rq->clock;
+
+	if (p == rq->idle)
+		schedstat_inc(rq->sched_goidle);
 #ifdef CONFIG_HIGH_RES_TIMERS
-	if (p != rq->idle)
+	else
 		hrtick_start(rq, p->time_slice);
 #endif
 }
@@ -3420,9 +3424,7 @@ static void __sched notrace __schedule(bool preempt)
 	set_rq_task(rq, next);
 
 	if (prev != next) {
-		if (MAX_PRIO == next->prio)
-			schedstat_inc(rq->sched_goidle);
-
+		rq->nr_switches++;
 		/*
 		 * RCU users of rcu_dereference(rq->curr) may not see
 		 * changes to task_struct made by pick_next_task().
@@ -3443,7 +3445,6 @@ static void __sched notrace __schedule(bool preempt)
 		 *   is a RELEASE barrier),
 		 */
 		++*switch_count;
-		rq->nr_switches++;
 		rq->last_ts_switch = rq->clock;
 
 		trace_sched_switch(preempt, prev, next);
@@ -5156,8 +5157,6 @@ void init_idle(struct task_struct *idle, int cpu)
 	idle->last_ran = rq->clock_task;
 	idle->state = TASK_RUNNING;
 	idle->flags |= PF_IDLE;
-	/* Setting prio to illegal value shouldn't matter as it will never be de/enqueued */
-	idle->prio = MAX_PRIO;
 	idle->bmq_idx = IDLE_TASK_SCHED_PRIO;
 	bmq_init_idle(&rq->queue, idle);
 
-- 
2.26.0.106.g9fadedd637


From 53bb18fc8f49ba0921f00368c0d88e24ca13cec6 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 31 Mar 2020 15:53:36 +0800
Subject: [PATCH 2/2] BMQ v5.6-r2

---
 kernel/sched/bmq.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index 0a9a56e3312a..b37608bbc23a 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -70,7 +70,7 @@ early_param("bmq.timeslice", sched_timeslice);
 
 static inline void print_scheduler_version(void)
 {
-	printk(KERN_INFO "bmq: BMQ CPU Scheduler 5.6-r1 by Alfred Chen.\n");
+	printk(KERN_INFO "bmq: BMQ CPU Scheduler 5.6-r2 by Alfred Chen.\n");
 }
 
 /**
-- 
2.26.0.106.g9fadedd637

