From ad2cfcbf34a7efba3b70adce95a56ef1ff398973 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Mon, 30 Mar 2020 10:30:42 +0800
Subject: [PATCH 1/5] bmq: Fix compile warning on 32bit system.

---
 kernel/sched/bmq.c | 6 +++---
 1 file changed, 3 insertions(+), 3 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index 58657044d58c..e4c1561e00e6 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -5554,10 +5554,10 @@ static void sched_init_topology_cpumask(void)
 			       cpu, (chk++)->bits[0]);
 
 		per_cpu(sched_cpu_affinity_end_mask, cpu) = chk;
-		printk(KERN_INFO "bmq: cpu#%d llc_id = %d, llc_mask idx = %ld\n",
+		printk(KERN_INFO "bmq: cpu#%d llc_id = %d, llc_mask idx = %d\n",
 		       cpu, per_cpu(sd_llc_id, cpu),
-		       per_cpu(sched_cpu_llc_mask, cpu) -
-		       &(per_cpu(sched_cpu_affinity_masks, cpu)[0]));
+		       (int) (per_cpu(sched_cpu_llc_mask, cpu) -
+			      &(per_cpu(sched_cpu_affinity_masks, cpu)[0])));
 	}
 }
 #endif
-- 
2.26.0.106.g9fadedd637


From ea018035c311216b024f4d0c305e4182ffbba3c9 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 17 Mar 2020 09:26:38 +0800
Subject: [PATCH 2/5] bmq: Revert cpufreq driver changes.

---
 drivers/cpufreq/cpufreq_conservative.c | 4 ++--
 drivers/cpufreq/cpufreq_ondemand.c     | 4 ++--
 2 files changed, 4 insertions(+), 4 deletions(-)

diff --git a/drivers/cpufreq/cpufreq_conservative.c b/drivers/cpufreq/cpufreq_conservative.c
index b5bc5a1b6de7..737ff3b9c2c0 100644
--- a/drivers/cpufreq/cpufreq_conservative.c
+++ b/drivers/cpufreq/cpufreq_conservative.c
@@ -28,8 +28,8 @@ struct cs_dbs_tuners {
 };
 
 /* Conservative governor macros */
-#define DEF_FREQUENCY_UP_THRESHOLD		(63)
-#define DEF_FREQUENCY_DOWN_THRESHOLD		(26)
+#define DEF_FREQUENCY_UP_THRESHOLD		(80)
+#define DEF_FREQUENCY_DOWN_THRESHOLD		(20)
 #define DEF_FREQUENCY_STEP			(5)
 #define DEF_SAMPLING_DOWN_FACTOR		(1)
 #define MAX_SAMPLING_DOWN_FACTOR		(10)
diff --git a/drivers/cpufreq/cpufreq_ondemand.c b/drivers/cpufreq/cpufreq_ondemand.c
index 1130e0f5db72..82a4d37ddecb 100644
--- a/drivers/cpufreq/cpufreq_ondemand.c
+++ b/drivers/cpufreq/cpufreq_ondemand.c
@@ -18,7 +18,7 @@
 #include "cpufreq_ondemand.h"
 
 /* On-demand governor macros */
-#define DEF_FREQUENCY_UP_THRESHOLD		(63)
+#define DEF_FREQUENCY_UP_THRESHOLD		(80)
 #define DEF_SAMPLING_DOWN_FACTOR		(1)
 #define MAX_SAMPLING_DOWN_FACTOR		(100000)
 #define MICRO_FREQUENCY_UP_THRESHOLD		(95)
@@ -127,7 +127,7 @@ static void dbs_freq_increase(struct cpufreq_policy *policy, unsigned int freq)
 }
 
 /*
- * Every sampling_rate, we check, if current idle time is less than 37%
+ * Every sampling_rate, we check, if current idle time is less than 20%
  * (default), then we try to increase frequency. Else, we adjust the frequency
  * proportional to load.
  */
-- 
2.26.0.106.g9fadedd637


From db7170069efecd46bcdd5784bce57e22b3579894 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 17 Mar 2020 09:47:35 +0800
Subject: [PATCH 3/5] bmq: Revert INITIAL_JIFFIES changes.

---
 include/linux/jiffies.h | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/include/linux/jiffies.h b/include/linux/jiffies.h
index 4e08b64c56b0..e3279ef24d28 100644
--- a/include/linux/jiffies.h
+++ b/include/linux/jiffies.h
@@ -171,7 +171,7 @@ static inline u64 get_jiffies_64(void)
  * Have the 32 bit jiffies value wrap 5 minutes after boot
  * so jiffies wrap bugs show up earlier.
  */
-#define INITIAL_JIFFIES ((unsigned long)(unsigned int) (-10*HZ))
+#define INITIAL_JIFFIES ((unsigned long)(unsigned int) (-300*HZ))
 
 /*
  * Change timeval to jiffies, trying to avoid the
-- 
2.26.0.106.g9fadedd637


From 9d77bff1a094f20ed20beb14f603be6c93d3adf3 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Thu, 19 Mar 2020 20:58:58 +0800
Subject: [PATCH 4/5] bmq: Extend BMQ for RT tasks.

---
 kernel/sched/bmq.c       | 35 ++++++-----------------------------
 kernel/sched/bmq_sched.h |  4 ++--
 2 files changed, 8 insertions(+), 31 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index e4c1561e00e6..d9cbbf677225 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -147,17 +147,9 @@ DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
 static cpumask_t sched_sg_idle_mask ____cacheline_aligned_in_smp;
 static cpumask_t sched_rq_watermark[bmq_BITS] ____cacheline_aligned_in_smp;
 
-#if (bmq_BITS <= BITS_PER_LONG)
-#define bmq_find_first_bit(bm)		__ffs((bm[0]))
-#define bmq_find_next_bit(bm, start)	__ffs(BITMAP_FIRST_WORD_MASK(start) & bm[0])
-#else
-#define bmq_find_first_bit(bm)		find_first_bit((bm), bmq_BITS)
-#define bmq_find_next_bit(bm, start)	find_next_bit(bm, bmq_BITS, start)
-#endif
-
 static inline void update_sched_rq_watermark(struct rq *rq)
 {
-	unsigned long watermark = bmq_find_first_bit(rq->queue.bitmap);
+	unsigned long watermark = find_first_bit(rq->queue.bitmap, bmq_BITS);
 	unsigned long last_wm = rq->watermark;
 	unsigned long i;
 	int cpu;
@@ -198,7 +190,7 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 
 static inline int task_sched_prio(struct task_struct *p)
 {
-	return (p->prio < MAX_RT_PRIO)? 0:p->prio - MAX_RT_PRIO + p->boost_prio + 1;
+	return (p->prio < MAX_RT_PRIO)? p->prio : p->prio + p->boost_prio;
 }
 
 static inline void bmq_init(struct bmq *q)
@@ -217,27 +209,12 @@ static inline void bmq_init_idle(struct bmq *q, struct task_struct *idle)
 	set_bit(IDLE_TASK_SCHED_PRIO, q->bitmap);
 }
 
-static inline void bmq_add_task(struct task_struct *p, struct bmq *q, int idx)
-{
-	struct list_head *n;
-
-	if (likely(idx)) {
-		list_add_tail(&p->bmq_node, &q->heads[idx]);
-		return;
-	}
-
-	list_for_each(n, &q->heads[idx])
-		if (list_entry(n, struct task_struct, bmq_node)->prio > p->prio)
-			break;
-	__list_add(&p->bmq_node, n->prev, n);
-}
-
 /*
  * This routine used in bmq scheduler only which assume the idle task in the bmq
  */
 static inline struct task_struct *rq_first_bmq_task(struct rq *rq)
 {
-	unsigned long idx = bmq_find_first_bit(rq->queue.bitmap);
+	unsigned long idx = find_first_bit(rq->queue.bitmap, bmq_BITS);
 	const struct list_head *head = &rq->queue.heads[idx];
 
 	return list_first_entry(head, struct task_struct, bmq_node);
@@ -250,7 +227,7 @@ rq_next_bmq_task(struct task_struct *p, struct rq *rq)
 	struct list_head *head = &rq->queue.heads[idx];
 
 	if (list_is_last(&p->bmq_node, head)) {
-		idx = bmq_find_next_bit(rq->queue.bitmap, idx + 1);
+		idx = find_next_bit(rq->queue.bitmap, bmq_BITS, idx + 1);
 		head = &rq->queue.heads[idx];
 
 		return list_first_entry(head, struct task_struct, bmq_node);
@@ -535,7 +512,7 @@ static inline void enqueue_task(struct task_struct *p, struct rq *rq, int flags)
 		  task_cpu(p), cpu_of(rq));
 
 	p->bmq_idx = task_sched_prio(p);
-	bmq_add_task(p, &rq->queue, p->bmq_idx);
+	list_add_tail(&p->bmq_node, &rq->queue.heads[p->bmq_idx]);
 	set_bit(p->bmq_idx, rq->queue.bitmap);
 	update_sched_rq_watermark(rq);
 	++rq->nr_running;
@@ -567,7 +544,7 @@ static inline void requeue_task(struct task_struct *p, struct rq *rq)
 		  cpu_of(rq), task_cpu(p));
 
 	list_del(&p->bmq_node);
-	bmq_add_task(p, &rq->queue, idx);
+	list_add_tail(&p->bmq_node, &rq->queue.heads[idx]);
 	if (idx != p->bmq_idx) {
 		if (list_empty(&rq->queue.heads[p->bmq_idx]))
 			clear_bit(p->bmq_idx, rq->queue.bitmap);
diff --git a/kernel/sched/bmq_sched.h b/kernel/sched/bmq_sched.h
index 6fc8ae438c32..fca42b270620 100644
--- a/kernel/sched/bmq_sched.h
+++ b/kernel/sched/bmq_sched.h
@@ -68,8 +68,8 @@ static inline int task_on_rq_migrating(struct task_struct *p)
 #define WF_MIGRATED	0x04		/* internal use, task got migrated */
 
 /* bits:
- * RT, Low prio adj range, nice width, high prio adj range, cpu idle task */
-#define bmq_BITS		(NICE_WIDTH + 2 * MAX_PRIORITY_ADJ + 2)
+ * RT(0-99), Low prio adj range, nice width, high prio adj range, cpu idle task */
+#define bmq_BITS	(MAX_RT_PRIO + NICE_WIDTH + 2 * MAX_PRIORITY_ADJ + 1)
 #define IDLE_TASK_SCHED_PRIO	(bmq_BITS - 1)
 
 struct bmq {
-- 
2.26.0.106.g9fadedd637


From d7240a362dd4aafb90a719f36d178a4a7b7eb3e2 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 31 Mar 2020 15:51:26 +0800
Subject: [PATCH 5/5] BMQ v5.6-r1

---
 kernel/sched/bmq.c | 2 +-
 1 file changed, 1 insertion(+), 1 deletion(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index d9cbbf677225..e6d6fc98bead 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -70,7 +70,7 @@ early_param("bmq.timeslice", sched_timeslice);
 
 static inline void print_scheduler_version(void)
 {
-	printk(KERN_INFO "bmq: BMQ CPU Scheduler 5.6-r0 by Alfred Chen.\n");
+	printk(KERN_INFO "bmq: BMQ CPU Scheduler 5.6-r1 by Alfred Chen.\n");
 }
 
 /**
-- 
2.26.0.106.g9fadedd637

