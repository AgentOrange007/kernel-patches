From 6ed4d4141e604a650bde8fe1c5f32bc08869a15d Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Fri, 28 Dec 2018 15:12:14 +0800
Subject: [PATCH 1/5] pds: Use exported task_rq_lock/unlock().

---
 kernel/livepatch/transition.c | 15 ++-------------
 kernel/sched/cputime.c        | 18 ------------------
 kernel/sched/pds.c            |  9 ++++++++-
 kernel/sched/pds_sched.h      | 11 -----------
 4 files changed, 10 insertions(+), 43 deletions(-)

diff --git a/kernel/livepatch/transition.c b/kernel/livepatch/transition.c
index af6575efd28c..d48c6a01e714 100644
--- a/kernel/livepatch/transition.c
+++ b/kernel/livepatch/transition.c
@@ -298,12 +298,7 @@ static int klp_check_stack(struct task_struct *task, char *err_buf)
 static bool klp_try_switch_task(struct task_struct *task)
 {
 	struct rq *rq;
-#ifdef	CONFIG_SCHED_PDS
-	raw_spinlock_t *lock;
-	unsigned long flags;
-#else
 	struct rq_flags flags;
-#endif
 	int ret;
 	bool success = false;
 	char err_buf[STACK_ERR_BUF_SIZE];
@@ -319,13 +314,11 @@ static bool klp_try_switch_task(struct task_struct *task)
 	 * functions.  If all goes well, switch the task to the target patch
 	 * state.
 	 */
-#ifdef	CONFIG_SCHED_PDS
-	rq = task_access_lock_irqsave(task, &lock, &flags);
+	rq = task_rq_lock(task, &flags);
 
+#ifdef	CONFIG_SCHED_PDS
 	if (task_running(task) && task != current) {
 #else
-	rq = task_rq_lock(task, &flags);
-
 	if (task_running(rq, task) && task != current) {
 #endif
 		snprintf(err_buf, STACK_ERR_BUF_SIZE,
@@ -344,11 +337,7 @@ static bool klp_try_switch_task(struct task_struct *task)
 	task->patch_state = klp_target_state;
 
 done:
-#ifdef	CONFIG_SCHED_PDS
-	task_access_unlock_irqrestore(task, lock, &flags);
-#else
 	task_rq_unlock(rq, task, &flags);
-#endif
 
 	/*
 	 * Due to console deadlock issues, pr_debug() can't be used while
diff --git a/kernel/sched/cputime.c b/kernel/sched/cputime.c
index d3b4d1528614..43606b14d746 100644
--- a/kernel/sched/cputime.c
+++ b/kernel/sched/cputime.c
@@ -280,22 +280,6 @@ static inline u64 read_sum_exec_runtime(struct task_struct *t)
 	return tsk_seruntime(t);
 }
 #else
-
-#ifdef	CONFIG_SCHED_PDS
-static u64 read_sum_exec_runtime(struct task_struct *t)
-{
-	u64 ns;
-	struct rq *rq;
-	raw_spinlock_t *lock;
-	unsigned long flags;
-
-	rq = task_access_lock_irqsave(t, &lock, &flags);
-	ns = tsk_seruntime(t);
-	task_access_unlock_irqrestore(t, lock, &flags);
-
-	return ns;
-}
-#else
 static u64 read_sum_exec_runtime(struct task_struct *t)
 {
 	u64 ns;
@@ -310,8 +294,6 @@ static u64 read_sum_exec_runtime(struct task_struct *t)
 }
 #endif
 
-#endif
-
 /*
  * Accumulate raw cputime values of dead tasks (sig->[us]time) and live
  * tasks (sum on group iteration) belonging to @tsk's group.
diff --git a/kernel/sched/pds.c b/kernel/sched/pds.c
index e8b60ad97414..2110c3fcd4d5 100644
--- a/kernel/sched/pds.c
+++ b/kernel/sched/pds.c
@@ -259,7 +259,7 @@ __task_access_unlock(struct task_struct *p, raw_spinlock_t *lock)
 		raw_spin_unlock(lock);
 }
 
-struct rq
+static inline struct rq
 *task_access_lock_irqsave(struct task_struct *p, raw_spinlock_t **plock,
 			  unsigned long *flags)
 {
@@ -290,6 +290,13 @@ struct rq
 	}
 }
 
+static inline void
+task_access_unlock_irqrestore(struct task_struct *p, raw_spinlock_t *lock,
+			      unsigned long *flags)
+{
+	raw_spin_unlock_irqrestore(lock, *flags);
+}
+
 /*
  * __task_rq_lock - lock the rq @p resides on.
  */
diff --git a/kernel/sched/pds_sched.h b/kernel/sched/pds_sched.h
index 5e5632c234db..17d3fc44b4b4 100644
--- a/kernel/sched/pds_sched.h
+++ b/kernel/sched/pds_sched.h
@@ -215,17 +215,6 @@ static inline u64 rq_clock_task(struct rq *rq)
 	return rq->clock_task;
 }
 
-struct rq
-*task_access_lock_irqsave(struct task_struct *p, raw_spinlock_t **plock,
-			  unsigned long *flags);
-
-static inline void
-task_access_unlock_irqrestore(struct task_struct *p, raw_spinlock_t *lock,
-			      unsigned long *flags)
-{
-	raw_spin_unlock_irqrestore(lock, *flags);
-}
-
 /*
  * {de,en}queue flags:
  *
-- 
2.20.1.98.gecbdaf0899

