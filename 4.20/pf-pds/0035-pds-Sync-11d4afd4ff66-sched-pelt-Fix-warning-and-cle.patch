From 4baba96d5a67347f6c90c6789a3b3ec971a8f302 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Tue, 4 Dec 2018 15:25:32 +0000
Subject: [PATCH 35/42] pds: [Sync] 11d4afd4ff66 sched/pelt: Fix warning and
 clean up IRQ PELT config

---
 kernel/sched/pds.c       | 7 +++----
 kernel/sched/pds_sched.h | 3 +--
 2 files changed, 4 insertions(+), 6 deletions(-)

diff --git a/kernel/sched/pds.c b/kernel/sched/pds.c
index 59804f449487..1ea0dd7be707 100644
--- a/kernel/sched/pds.c
+++ b/kernel/sched/pds.c
@@ -314,9 +314,8 @@ static void update_rq_clock_task(struct rq *rq, s64 delta)
  * In theory, the compile should just see 0 here, and optimize out the call
  * to sched_rt_avg_update. But I don't trust it...
  */
-#if defined(CONFIG_IRQ_TIME_ACCOUNTING) || defined(CONFIG_PARAVIRT_TIME_ACCOUNTING)
-	s64 steal = 0, irq_delta = 0;
-#endif
+	s64 __maybe_unused steal = 0, irq_delta = 0;
+
 #ifdef CONFIG_IRQ_TIME_ACCOUNTING
 	irq_delta = irq_time_read(cpu_of(rq)) - rq->prev_irq_time;
 
@@ -357,7 +356,7 @@ static void update_rq_clock_task(struct rq *rq, s64 delta)
 
 	rq->clock_task += delta;
 
-#ifdef HAVE_SCHED_AVG_IRQ
+#ifdef CONFIG_HAVE_SCHED_AVG_IRQ
 	if ((irq_delta + steal))
 		update_irq_load_avg(rq, irq_delta + steal);
 #endif
diff --git a/kernel/sched/pds_sched.h b/kernel/sched/pds_sched.h
index 194e4d6eaa58..682a19cbecd6 100644
--- a/kernel/sched/pds_sched.h
+++ b/kernel/sched/pds_sched.h
@@ -66,8 +66,7 @@ struct rq {
 	int cpu;		/* cpu of this runqueue */
 	bool online;
 
-#if defined(CONFIG_IRQ_TIME_ACCOUNTING) || defined(CONFIG_PARAVIRT_TIME_ACCOUNTING)
-#define HAVE_SCHED_AVG_IRQ
+#ifdef CONFIG_HAVE_SCHED_AVG_IRQ
 	struct sched_avg	avg_irq;
 #endif
 
-- 
2.20.1.2.gb21ebb671b

