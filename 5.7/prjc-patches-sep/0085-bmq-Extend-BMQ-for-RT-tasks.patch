From 63e66880a3024cbcc0ee981b065bff83507144e4 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Thu, 19 Mar 2020 20:58:58 +0800
Subject: [PATCH 085/112] bmq: Extend BMQ for RT tasks.

---
 kernel/sched/bmq.c       | 35 ++++++-----------------------------
 kernel/sched/bmq_sched.h |  4 ++--
 2 files changed, 8 insertions(+), 31 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index e4c1561e00e6..d9cbbf677225 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -147,17 +147,9 @@ DEFINE_PER_CPU_SHARED_ALIGNED(struct rq, runqueues);
 static cpumask_t sched_sg_idle_mask ____cacheline_aligned_in_smp;
 static cpumask_t sched_rq_watermark[bmq_BITS] ____cacheline_aligned_in_smp;
 
-#if (bmq_BITS <= BITS_PER_LONG)
-#define bmq_find_first_bit(bm)		__ffs((bm[0]))
-#define bmq_find_next_bit(bm, start)	__ffs(BITMAP_FIRST_WORD_MASK(start) & bm[0])
-#else
-#define bmq_find_first_bit(bm)		find_first_bit((bm), bmq_BITS)
-#define bmq_find_next_bit(bm, start)	find_next_bit(bm, bmq_BITS, start)
-#endif
-
 static inline void update_sched_rq_watermark(struct rq *rq)
 {
-	unsigned long watermark = bmq_find_first_bit(rq->queue.bitmap);
+	unsigned long watermark = find_first_bit(rq->queue.bitmap, bmq_BITS);
 	unsigned long last_wm = rq->watermark;
 	unsigned long i;
 	int cpu;
@@ -198,7 +190,7 @@ static inline void update_sched_rq_watermark(struct rq *rq)
 
 static inline int task_sched_prio(struct task_struct *p)
 {
-	return (p->prio < MAX_RT_PRIO)? 0:p->prio - MAX_RT_PRIO + p->boost_prio + 1;
+	return (p->prio < MAX_RT_PRIO)? p->prio : p->prio + p->boost_prio;
 }
 
 static inline void bmq_init(struct bmq *q)
@@ -217,27 +209,12 @@ static inline void bmq_init_idle(struct bmq *q, struct task_struct *idle)
 	set_bit(IDLE_TASK_SCHED_PRIO, q->bitmap);
 }
 
-static inline void bmq_add_task(struct task_struct *p, struct bmq *q, int idx)
-{
-	struct list_head *n;
-
-	if (likely(idx)) {
-		list_add_tail(&p->bmq_node, &q->heads[idx]);
-		return;
-	}
-
-	list_for_each(n, &q->heads[idx])
-		if (list_entry(n, struct task_struct, bmq_node)->prio > p->prio)
-			break;
-	__list_add(&p->bmq_node, n->prev, n);
-}
-
 /*
  * This routine used in bmq scheduler only which assume the idle task in the bmq
  */
 static inline struct task_struct *rq_first_bmq_task(struct rq *rq)
 {
-	unsigned long idx = bmq_find_first_bit(rq->queue.bitmap);
+	unsigned long idx = find_first_bit(rq->queue.bitmap, bmq_BITS);
 	const struct list_head *head = &rq->queue.heads[idx];
 
 	return list_first_entry(head, struct task_struct, bmq_node);
@@ -250,7 +227,7 @@ rq_next_bmq_task(struct task_struct *p, struct rq *rq)
 	struct list_head *head = &rq->queue.heads[idx];
 
 	if (list_is_last(&p->bmq_node, head)) {
-		idx = bmq_find_next_bit(rq->queue.bitmap, idx + 1);
+		idx = find_next_bit(rq->queue.bitmap, bmq_BITS, idx + 1);
 		head = &rq->queue.heads[idx];
 
 		return list_first_entry(head, struct task_struct, bmq_node);
@@ -535,7 +512,7 @@ static inline void enqueue_task(struct task_struct *p, struct rq *rq, int flags)
 		  task_cpu(p), cpu_of(rq));
 
 	p->bmq_idx = task_sched_prio(p);
-	bmq_add_task(p, &rq->queue, p->bmq_idx);
+	list_add_tail(&p->bmq_node, &rq->queue.heads[p->bmq_idx]);
 	set_bit(p->bmq_idx, rq->queue.bitmap);
 	update_sched_rq_watermark(rq);
 	++rq->nr_running;
@@ -567,7 +544,7 @@ static inline void requeue_task(struct task_struct *p, struct rq *rq)
 		  cpu_of(rq), task_cpu(p));
 
 	list_del(&p->bmq_node);
-	bmq_add_task(p, &rq->queue, idx);
+	list_add_tail(&p->bmq_node, &rq->queue.heads[idx]);
 	if (idx != p->bmq_idx) {
 		if (list_empty(&rq->queue.heads[p->bmq_idx]))
 			clear_bit(p->bmq_idx, rq->queue.bitmap);
diff --git a/kernel/sched/bmq_sched.h b/kernel/sched/bmq_sched.h
index 6fc8ae438c32..fca42b270620 100644
--- a/kernel/sched/bmq_sched.h
+++ b/kernel/sched/bmq_sched.h
@@ -68,8 +68,8 @@ static inline int task_on_rq_migrating(struct task_struct *p)
 #define WF_MIGRATED	0x04		/* internal use, task got migrated */
 
 /* bits:
- * RT, Low prio adj range, nice width, high prio adj range, cpu idle task */
-#define bmq_BITS		(NICE_WIDTH + 2 * MAX_PRIORITY_ADJ + 2)
+ * RT(0-99), Low prio adj range, nice width, high prio adj range, cpu idle task */
+#define bmq_BITS	(MAX_RT_PRIO + NICE_WIDTH + 2 * MAX_PRIORITY_ADJ + 1)
 #define IDLE_TASK_SCHED_PRIO	(bmq_BITS - 1)
 
 struct bmq {
-- 
2.27.0.112.g101b3204f3

