From 6c73299c62f4db7e0fdde58b531cc87df14889bc Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Wed, 30 Oct 2019 14:03:59 +0800
Subject: [PATCH 49/63] bmq: [Sync] a49b4f4012ef sched/core: Fix
 preempt_schedule() interrupt return comment

---
 kernel/sched/bmq.c | 7 +++----
 1 file changed, 3 insertions(+), 4 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index 89c1fe35f174..2e1cb54d945f 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -3272,9 +3272,8 @@ static void __sched notrace preempt_schedule_common(void)
 
 #ifdef CONFIG_PREEMPTION
 /*
- * this is the entry point to schedule() from in-kernel preemption
- * off of preempt_enable. Kernel preemptions off return from interrupt
- * occur there and call schedule directly.
+ * This is the entry point to schedule() from in-kernel preemption
+ * off of preempt_enable.
  */
 asmlinkage __visible void __sched notrace preempt_schedule(void)
 {
@@ -3345,7 +3344,7 @@ EXPORT_SYMBOL_GPL(preempt_schedule_notrace);
 #endif /* CONFIG_PREEMPTION */
 
 /*
- * this is the entry point to schedule() from kernel preemption
+ * This is the entry point to schedule() from kernel preemption
  * off of irq context.
  * Note, that this is called and return with irqs disabled. This will
  * protect us against recursive calling from irq.
-- 
2.25.0.2.g232378479e.dirty

