From a7103b05afb901882267696bb777a12866a57ea8 Mon Sep 17 00:00:00 2001
From: Alfred Chen <cchalpha@gmail.com>
Date: Thu, 21 Mar 2019 16:21:03 +0800
Subject: [PATCH 22/64] bmq: Rework task switch time thresholds.

---
 kernel/sched/bmq.c | 64 +++++++++++++++++++++-------------------------
 1 file changed, 29 insertions(+), 35 deletions(-)

diff --git a/kernel/sched/bmq.c b/kernel/sched/bmq.c
index e838f2a6fb3d..554a8e01ae94 100644
--- a/kernel/sched/bmq.c
+++ b/kernel/sched/bmq.c
@@ -66,38 +66,32 @@ static inline void print_scheduler_version(void)
  */
 int sched_yield_type __read_mostly = 1;
 
-static inline int ts_overrun(struct task_struct *p, struct rq *rq)
-{
-	const static u64 ts_overrun_th[] = {
-		SCHED_TIMESLICE_NS / 2,
-		SCHED_TIMESLICE_NS / 2,
-		SCHED_TIMESLICE_NS / 2,
-		SCHED_TIMESLICE_NS / 2,
-		SCHED_TIMESLICE_NS * 3 / 4,
-		SCHED_TIMESLICE_NS * 7 / 8,
-		SCHED_TIMESLICE_NS * 15 / 16,
-		SCHED_TIMESLICE_NS * 31 / 32,
-		SCHED_TIMESLICE_NS * 63 / 64};
-	return (rq->clock - rq->last_ts_switch >
-		ts_overrun_th[MAX_PRIORITY_ADJ + p->boost_prio]);
-}
-
-static inline int task_normal_boost(struct task_struct *p, struct rq *rq)
-{
-	const static u64 ts_nonboost_th[] = {
-		SCHED_TIMESLICE_NS << 7,
-		SCHED_TIMESLICE_NS << 6,
-		SCHED_TIMESLICE_NS << 5,
-		SCHED_TIMESLICE_NS << 4,
-		SCHED_TIMESLICE_NS << 3,
-		SCHED_TIMESLICE_NS << 3,
-		SCHED_TIMESLICE_NS << 3,
-		SCHED_TIMESLICE_NS << 3,
-		SCHED_TIMESLICE_NS << 3
-	};
-	return ((rq->clock - rq->last_ts_switch) >
-		ts_nonboost_th[MAX_PRIORITY_ADJ + p->boost_prio]);
-}
+const static u64 ts_overrun_th[] = {
+	SCHED_TIMESLICE_NS / 8,
+	SCHED_TIMESLICE_NS / 4,
+	SCHED_TIMESLICE_NS / 2,
+	SCHED_TIMESLICE_NS * 3 / 4,
+	SCHED_TIMESLICE_NS * 7 / 8,
+	SCHED_TIMESLICE_NS * 15 / 16,
+	SCHED_TIMESLICE_NS * 31 / 32,
+	SCHED_TIMESLICE_NS * 63 / 64,
+	SCHED_TIMESLICE_NS * 127 / 128
+};
+
+const static u64 ts_nonboost_th[] = {
+	SCHED_TIMESLICE_NS >> 8,
+	SCHED_TIMESLICE_NS >> 7,
+	SCHED_TIMESLICE_NS >> 6,
+	SCHED_TIMESLICE_NS >> 5,
+	SCHED_TIMESLICE_NS >> 4,
+	SCHED_TIMESLICE_NS >> 3,
+	SCHED_TIMESLICE_NS >> 2,
+	SCHED_TIMESLICE_NS >> 1,
+	SCHED_TIMESLICE_NS >> 1
+};
+
+#define TASK_ST_OVER(p, rq, th)	(((rq)->clock - (rq)->last_ts_switch) > \
+				 (th)[MAX_PRIORITY_ADJ +  (p)->boost_prio])
 
 #ifdef CONFIG_SMP
 static cpumask_t sched_rq_pending_mask ____cacheline_aligned_in_smp;
@@ -2858,7 +2852,7 @@ static inline void check_curr(struct task_struct *p, struct rq *rq)
 		p->time_slice = SCHED_TIMESLICE_NS;
 		if (SCHED_FIFO != p->policy && task_on_rq_queued(p)) {
 			if (SCHED_RR != p->policy &&
-			    (p->ts_deboost || ts_overrun(p, rq)))
+			    (p->ts_deboost || TASK_ST_OVER(p, rq, ts_overrun_th)))
 				deboost_task(p, MAX_PRIORITY_ADJ);
 			requeue_task(p, rq);
 		}
@@ -3106,9 +3100,9 @@ static void __sched notrace __schedule(bool preempt)
 		if (signal_pending_state(prev->state, prev)) {
 			prev->state = TASK_RUNNING;
 		} else {
-			prev->ts_deboost |= ts_overrun(prev, rq);
+			prev->ts_deboost |= TASK_ST_OVER(prev, rq, ts_overrun_th);
 			if ((SCHED_NORMAL == prev->policy &&
-			     task_normal_boost(prev, rq)) ||
+			     TASK_ST_OVER(prev, rq, ts_nonboost_th)) ||
 			    SCHED_BATCH == prev->policy ||
 			    SCHED_IDLE == prev->policy)
 				deboost_task(prev, 1);
-- 
2.22.0.214.g8dca754b1e

